---
title: k8så•masterèŠ‚ç‚¹å®‰è£…
author: starifly
date: 2020-11-29T14:55:48+08:00
lastmod: 2020-12-01T21:57:48+08:00
categories: [k8s]
tags: [k8s,docker]
draft: true
slug: k8s-single-master-node-installation
---

ä½¿ç”¨kubeadmå®‰è£…kubernetes_v1.19.x

## é…ç½®è¦æ±‚

å¯¹äº Kubernetes åˆå­¦è€…ï¼Œåœ¨æ­å»ºK8Sé›†ç¾¤æ—¶ï¼Œæ¨èåœ¨é˜¿é‡Œäº‘æˆ–è…¾è®¯äº‘é‡‡è´­å¦‚ä¸‹é…ç½®ï¼šï¼ˆæ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨è‡ªå·±çš„è™šæ‹Ÿæœºã€ç§æœ‰äº‘ç­‰æ‚¨æœ€å®¹æ˜“è·å¾—çš„ Linux ç¯å¢ƒï¼‰

- è‡³å°‘2å° 2æ ¸4G çš„æœåŠ¡å™¨
- Cent OS 7.6 / 7.7 / 7.8

**å®‰è£…åçš„è½¯ä»¶ç‰ˆæœ¬ä¸º**

* Kubernetes v1.19.x
  * calico 3.13.1
  * nginx-ingress 1.5.5
* Docker 19.03.11

> å¦‚æœè¦å®‰è£… Kubernetes å†å²ç‰ˆæœ¬ï¼Œè¯·å‚è€ƒï¼š
> * [å®‰è£… Kubernetes v1.18.x å•MasterèŠ‚ç‚¹](/install/history-k8s/install-k8s-1.18.x.html)
> * [å®‰è£… Kubernetes v1.17.x å•MasterèŠ‚ç‚¹](/install/history-k8s/install-k8s-1.17.x.html)
> * [å®‰è£… Kubernetes v1.16.3 å•MasterèŠ‚ç‚¹](/install/history-k8s/install-k8s-1.16.3.html)
> * [å®‰è£… Kubernetes v1.15.4 å•MasterèŠ‚ç‚¹](/install/history-k8s/install-k8s-1.15.4.html)

å®‰è£…åçš„æ‹“æ‰‘å›¾å¦‚ä¸‹ï¼š<span v-on:click="$sendGaEvent('ä¸‹è½½æ‹“æ‰‘å›¾-kubernetes', 'ä¸‹è½½æ‹“æ‰‘å›¾-kubernetes', 'Download-install-kubernetes.html')"><a :href="$withBase('/kuboard.rp')" download="www.kuboard.cn.rp">ä¸‹è½½æ‹“æ‰‘å›¾æºæ–‡ä»¶</a></span> <font color="#999">ä½¿ç”¨Axure RP 9.0å¯æ‰“å¼€è¯¥æ–‡ä»¶</font>

## æ£€æŸ¥ centos / hostname

``` sh
# åœ¨ master èŠ‚ç‚¹å’Œ worker èŠ‚ç‚¹éƒ½è¦æ‰§è¡Œ
cat /etc/redhat-release

# æ­¤å¤„ hostname çš„è¾“å‡ºå°†ä¼šæ˜¯è¯¥æœºå™¨åœ¨ Kubernetes é›†ç¾¤ä¸­çš„èŠ‚ç‚¹åå­—
# ä¸èƒ½ä½¿ç”¨ localhost ä½œä¸ºèŠ‚ç‚¹çš„åå­—
hostname

# è¯·ä½¿ç”¨ lscpu å‘½ä»¤ï¼Œæ ¸å¯¹ CPU ä¿¡æ¯
# Architecture: x86_64    æœ¬å®‰è£…æ–‡æ¡£ä¸æ”¯æŒ arm æ¶æ„
# CPU(s):       2         CPU å†…æ ¸æ•°é‡ä¸èƒ½ä½äº 2
lscpu
```

**æ“ä½œç³»ç»Ÿå…¼å®¹æ€§**

| CentOS ç‰ˆæœ¬ | æœ¬æ–‡æ¡£æ˜¯å¦å…¼å®¹                          | å¤‡æ³¨                                |
| ----------- | --------------------------------------- | ----------------------------------- |
| 7.8         | <span style="font-size: 24px;">í ½í¸„</span> | å·²éªŒè¯                              |
| 7.7         | <span style="font-size: 24px;">í ½í¸„</span> | å·²éªŒè¯                              |
| 7.6         | <span style="font-size: 24px;">í ½í¸„</span> | å·²éªŒè¯                              |
| 7.5         | <span style="font-size: 24px;">í ½í¸</span> | å·²è¯å®ä¼šå‡ºç° kubelet æ— æ³•å¯åŠ¨çš„é—®é¢˜    |
| 7.4         | <span style="font-size: 24px;">í ½í¸</span> | å·²è¯å®ä¼šå‡ºç° kubelet æ— æ³•å¯åŠ¨çš„é—®é¢˜                              |
| 7.3         | <span style="font-size: 24px;">í ½í¸</span> | å·²è¯å®ä¼šå‡ºç° kubelet æ— æ³•å¯åŠ¨çš„é—®é¢˜                              |
| 7.2         | <span style="font-size: 24px;">í ½í¸</span> | å·²è¯å®ä¼šå‡ºç° kubelet æ— æ³•å¯åŠ¨çš„é—®é¢˜                              |

> **ä¿®æ”¹ hostname**
> å¦‚æœæ‚¨éœ€è¦ä¿®æ”¹ hostnameï¼Œå¯æ‰§è¡Œå¦‚ä¸‹æŒ‡ä»¤ï¼š


``` sh
# ä¿®æ”¹ hostname
hostnamectl set-hostname your-new-host-name
# æŸ¥çœ‹ä¿®æ”¹ç»“æœ
hostnamectl status
# è®¾ç½® hostname è§£æ
echo "127.0.0.1   $(hostname)" >> /etc/hosts
```

## å®‰è£…dockeråŠkubelet

ä½¿ç”¨ root èº«ä»½åœ¨æ‰€æœ‰èŠ‚ç‚¹æ‰§è¡Œå¦‚ä¸‹ä»£ç ï¼Œä»¥å®‰è£…è½¯ä»¶ï¼š
- docker
- nfs-utils
- kubectl / kubeadm / kubelet

> docker hub é•œåƒè¯·æ ¹æ®è‡ªå·±ç½‘ç»œçš„æƒ…å†µä»»é€‰ä¸€ä¸ª
> * ç¬¬å››è¡Œä¸ºè…¾è®¯äº‘ docker hub é•œåƒ
> * ç¬¬å…­è¡Œä¸ºDaoCloud docker hub é•œåƒ
> * ç¬¬å…«è¡Œä¸ºé˜¿é‡Œäº‘ docker hub é•œåƒ

``` sh
# åœ¨ master èŠ‚ç‚¹å’Œ worker èŠ‚ç‚¹éƒ½è¦æ‰§è¡Œ
# æœ€åä¸€ä¸ªå‚æ•° 1.19.2 ç”¨äºæŒ‡å®š kubenetes ç‰ˆæœ¬ï¼Œæ”¯æŒæ‰€æœ‰ 1.19.x ç‰ˆæœ¬çš„å®‰è£…
# è…¾è®¯äº‘ docker hub é•œåƒ
# export REGISTRY_MIRROR="https://mirror.ccs.tencentyun.com"
# DaoCloud é•œåƒ
# export REGISTRY_MIRROR="http://f1361db2.m.daocloud.io"
# é˜¿é‡Œäº‘ docker hub é•œåƒ
export REGISTRY_MIRROR=https://registry.cn-hangzhou.aliyuncs.com
```

å®‰è£…è„šæœ¬ï¼Œåœ¨ master èŠ‚ç‚¹å’Œ worker èŠ‚ç‚¹éƒ½è¦æ‰§è¡Œï¼Œè¯·å°†è„šæœ¬ç¬¬79è¡Œï¼ˆå·²é«˜äº®ï¼‰çš„ $1 æ›¿æ¢æˆæ‚¨éœ€è¦çš„ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ 1.19.2

``` sh
#!/bin/bash

# åœ¨ master èŠ‚ç‚¹å’Œ worker èŠ‚ç‚¹éƒ½è¦æ‰§è¡Œ

# å®‰è£… docker
# å‚è€ƒæ–‡æ¡£å¦‚ä¸‹
# https://docs.docker.com/install/linux/docker-ce/centos/ 
# https://docs.docker.com/install/linux/linux-postinstall/

# å¸è½½æ—§ç‰ˆæœ¬
yum remove -y docker \
docker-client \
docker-client-latest \
docker-ce-cli \
docker-common \
docker-latest \
docker-latest-logrotate \
docker-logrotate \
docker-selinux \
docker-engine-selinux \
docker-engine

# è®¾ç½® yum repository
yum install -y yum-utils \
device-mapper-persistent-data \
lvm2
yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo

# å®‰è£…å¹¶å¯åŠ¨ docker
yum install -y docker-ce-19.03.11 docker-ce-cli-19.03.11 containerd.io-1.2.13

mkdir /etc/docker || true

cat > /etc/docker/daemon.json <<EOF
{
  "registry-mirrors": ["${REGISTRY_MIRROR}"],
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2",
  "storage-opts": [
    "overlay2.override_kernel_check=true"
  ]
}
EOF

mkdir -p /etc/systemd/system/docker.service.d

# Restart Docker
systemctl daemon-reload
systemctl enable docker
systemctl restart docker

# å®‰è£… nfs-utils
# å¿…é¡»å…ˆå®‰è£… nfs-utils æ‰èƒ½æŒ‚è½½ nfs ç½‘ç»œå­˜å‚¨
yum install -y nfs-utils
yum install -y wget

# å…³é—­ é˜²ç«å¢™
systemctl stop firewalld
systemctl disable firewalld

# å…³é—­ SeLinux
setenforce 0
sed -i "s/SELINUX=enforcing/SELINUX=disabled/g" /etc/selinux/config

# å…³é—­ swap
swapoff -a
yes | cp /etc/fstab /etc/fstab_bak
cat /etc/fstab_bak |grep -v swap > /etc/fstab

# ä¿®æ”¹ /etc/sysctl.conf
# å¦‚æœæœ‰é…ç½®ï¼Œåˆ™ä¿®æ”¹
sed -i "s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g"  /etc/sysctl.conf
sed -i "s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g"  /etc/sysctl.conf
sed -i "s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g"  /etc/sysctl.conf
sed -i "s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g"  /etc/sysctl.conf
sed -i "s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g"  /etc/sysctl.conf
sed -i "s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g"  /etc/sysctl.conf
sed -i "s#^net.ipv6.conf.all.forwarding.*#net.ipv6.conf.all.forwarding=1#g"  /etc/sysctl.conf
# å¯èƒ½æ²¡æœ‰ï¼Œè¿½åŠ 
echo "net.ipv4.ip_forward = 1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-ip6tables = 1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-iptables = 1" >> /etc/sysctl.conf
echo "net.ipv6.conf.all.disable_ipv6 = 1" >> /etc/sysctl.conf
echo "net.ipv6.conf.default.disable_ipv6 = 1" >> /etc/sysctl.conf
echo "net.ipv6.conf.lo.disable_ipv6 = 1" >> /etc/sysctl.conf
echo "net.ipv6.conf.all.forwarding = 1"  >> /etc/sysctl.conf
# æ‰§è¡Œå‘½ä»¤ä»¥åº”ç”¨
sysctl -p

# é…ç½®K8Sçš„yumæº
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=0
repo_gpgcheck=0
gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
EOF

# å¸è½½æ—§ç‰ˆæœ¬
yum remove -y kubelet kubeadm kubectl

# å®‰è£…kubeletã€kubeadmã€kubectl
# å°† $1 æ›¿æ¢ä¸º kubernetes ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ 1.19.0
yum install -y kubelet-$1 kubeadm-$1 kubectl-$1

# é‡å¯ dockerï¼Œå¹¶å¯åŠ¨ kubelet
systemctl daemon-reload
systemctl restart docker
systemctl enable kubelet && systemctl start kubelet

docker version
```

> warning
> å¦‚æœæ­¤æ—¶æ‰§è¡Œ `systemctl status kubelet` å‘½ä»¤ï¼Œå°†å¾—åˆ° kubelet å¯åŠ¨å¤±è´¥çš„é”™è¯¯æç¤ºï¼Œè¯·å¿½ç•¥æ­¤é”™è¯¯ï¼Œå› ä¸ºå¿…é¡»å®Œæˆåç»­æ­¥éª¤ä¸­ kubeadm init çš„æ“ä½œï¼Œkubelet æ‰èƒ½æ­£å¸¸å¯åŠ¨

## åˆå§‹åŒ– master èŠ‚ç‚¹

> å…³äºåˆå§‹åŒ–æ—¶ç”¨åˆ°çš„ç¯å¢ƒå˜é‡
> * **APISERVER_NAME** ä¸èƒ½æ˜¯ master çš„ hostname
> * **APISERVER_NAME** å¿…é¡»å…¨ä¸ºå°å†™å­—æ¯ã€æ•°å­—ã€å°æ•°ç‚¹ï¼Œä¸èƒ½åŒ…å«å‡å·
> * **POD_SUBNET** æ‰€ä½¿ç”¨çš„ç½‘æ®µä¸èƒ½ä¸ ***masterèŠ‚ç‚¹/workerèŠ‚ç‚¹*** æ‰€åœ¨çš„ç½‘æ®µé‡å ã€‚è¯¥å­—æ®µçš„å–å€¼ä¸ºä¸€ä¸ª <a href="/glossary/cidr.html" target="_blank">CIDR</a> å€¼ï¼Œå¦‚æœæ‚¨å¯¹ CIDR è¿™ä¸ªæ¦‚å¿µè¿˜ä¸ç†Ÿæ‚‰ï¼Œè¯·ä»ç„¶æ‰§è¡Œ export POD_SUBNET=10.100.0.1/16 å‘½ä»¤ï¼Œä¸åšä¿®æ”¹

æ‰‹åŠ¨æ‰§è¡Œä»¥ä¸‹ä»£ç 

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
# æ›¿æ¢ x.x.x.x ä¸º master èŠ‚ç‚¹çš„å†…ç½‘IP
# export å‘½ä»¤åªåœ¨å½“å‰ shell ä¼šè¯ä¸­æœ‰æ•ˆï¼Œå¼€å¯æ–°çš„ shell çª—å£åï¼Œå¦‚æœè¦ç»§ç»­å®‰è£…è¿‡ç¨‹ï¼Œè¯·é‡æ–°æ‰§è¡Œæ­¤å¤„çš„ export å‘½ä»¤
export MASTER_IP=x.x.x.x
# æ›¿æ¢ apiserver.demo ä¸º æ‚¨æƒ³è¦çš„ dnsName
export APISERVER_NAME=apiserver.demo
# Kubernetes å®¹å™¨ç»„æ‰€åœ¨çš„ç½‘æ®µï¼Œè¯¥ç½‘æ®µå®‰è£…å®Œæˆåï¼Œç”± kubernetes åˆ›å»ºï¼Œäº‹å…ˆå¹¶ä¸å­˜åœ¨äºæ‚¨çš„ç‰©ç†ç½‘ç»œä¸­
export POD_SUBNET=10.100.0.1/16
echo "${MASTER_IP}    ${APISERVER_NAME}" >> /etc/hosts
```

åˆå§‹åŒ–è„šæœ¬ï¼Œåªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œï¼Œè¯·å°†è„šæœ¬ç¬¬21è¡Œï¼ˆå·²é«˜äº®ï¼‰çš„ $1 æ›¿æ¢æˆæ‚¨éœ€è¦çš„ç‰ˆæœ¬å·ï¼Œä¾‹å¦‚ 1.19.2

``` sh
#!/bin/bash

# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ

# è„šæœ¬å‡ºé”™æ—¶ç»ˆæ­¢æ‰§è¡Œ
set -e

if [ ${#POD_SUBNET} -eq 0 ] || [ ${#APISERVER_NAME} -eq 0 ]; then
  echo -e "\033[31;1mè¯·ç¡®ä¿æ‚¨å·²ç»è®¾ç½®äº†ç¯å¢ƒå˜é‡ POD_SUBNET å’Œ APISERVER_NAME \033[0m"
  echo å½“å‰POD_SUBNET=$POD_SUBNET
  echo å½“å‰APISERVER_NAME=$APISERVER_NAME
  exit 1
fi


# æŸ¥çœ‹å®Œæ•´é…ç½®é€‰é¡¹ https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2
rm -f ./kubeadm-config.yaml
cat <<EOF > ./kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v$1
imageRepository: registry.aliyuncs.com/k8sxio
controlPlaneEndpoint: "${APISERVER_NAME}:6443"
networking:
  serviceSubnet: "10.96.0.0/16"
  podSubnet: "${POD_SUBNET}"
  dnsDomain: "cluster.local"
EOF

# kubeadm init
# æ ¹æ®æ‚¨æœåŠ¡å™¨ç½‘é€Ÿçš„æƒ…å†µï¼Œæ‚¨éœ€è¦ç­‰å€™ 3 - 10 åˆ†é’Ÿ
kubeadm init --config=kubeadm-config.yaml --upload-certs

# é…ç½® kubectl
rm -rf /root/.kube/
mkdir /root/.kube/
cp -i /etc/kubernetes/admin.conf /root/.kube/config

# å®‰è£… calico ç½‘ç»œæ’ä»¶
# å‚è€ƒæ–‡æ¡£ https://docs.projectcalico.org/v3.13/getting-started/kubernetes/self-managed-onprem/onpremises
echo "å®‰è£…calico-3.13.1"
rm -f calico-3.13.1.yaml
wget https://kuboard.cn/install-script/calico/calico-3.13.1.yaml
kubectl apply -f calico-3.13.1.yaml
```
calico-3.13.1.yamlæ–‡ä»¶å†…å®¹ï¼Œè¿™é‡Œåªä½œå¤‡ä»½ï¼š

``` yaml
---
# Source: calico/templates/calico-config.yaml
# This ConfigMap is used to configure a self-hosted Calico installation.
kind: ConfigMap
apiVersion: v1
metadata:
  name: calico-config
  namespace: kube-system
data:
  # Typha is disabled.
  typha_service_name: "none"
  # Configure the backend to use.
  calico_backend: "bird"

  # Configure the MTU to use
  veth_mtu: "1440"

  # The CNI network configuration to install on each node.  The special
  # values in this config will be automatically populated.
  cni_network_config: |-
    {
      "name": "k8s-pod-network",
      "cniVersion": "0.3.1",
      "plugins": [
        {
          "type": "calico",
          "log_level": "info",
          "datastore_type": "kubernetes",
          "nodename": "__KUBERNETES_NODE_NAME__",
          "mtu": __CNI_MTU__,
          "ipam": {
              "type": "calico-ipam"
          },
          "policy": {
              "type": "k8s"
          },
          "kubernetes": {
              "kubeconfig": "__KUBECONFIG_FILEPATH__"
          }
        },
        {
          "type": "portmap",
          "snat": true,
          "capabilities": {"portMappings": true}
        },
        {
          "type": "bandwidth",
          "capabilities": {"bandwidth": true}
        }
      ]
    }

---
# Source: calico/templates/kdd-crds.yaml

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgpconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPConfiguration
    plural: bgpconfigurations
    singular: bgpconfiguration

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgppeers.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BGPPeer
    plural: bgppeers
    singular: bgppeer

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: blockaffinities.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: BlockAffinity
    plural: blockaffinities
    singular: blockaffinity

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: clusterinformations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: ClusterInformation
    plural: clusterinformations
    singular: clusterinformation

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: felixconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: FelixConfiguration
    plural: felixconfigurations
    singular: felixconfiguration

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworkpolicies.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkPolicy
    plural: globalnetworkpolicies
    singular: globalnetworkpolicy

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworksets.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: GlobalNetworkSet
    plural: globalnetworksets
    singular: globalnetworkset

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: hostendpoints.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: HostEndpoint
    plural: hostendpoints
    singular: hostendpoint

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamblocks.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMBlock
    plural: ipamblocks
    singular: ipamblock

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamconfigs.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMConfig
    plural: ipamconfigs
    singular: ipamconfig

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ipamhandles.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPAMHandle
    plural: ipamhandles
    singular: ipamhandle

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ippools.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  version: v1
  names:
    kind: IPPool
    plural: ippools
    singular: ippool

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: networkpolicies.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkPolicy
    plural: networkpolicies
    singular: networkpolicy

---
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: networksets.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  version: v1
  names:
    kind: NetworkSet
    plural: networksets
    singular: networkset

---
---
# Source: calico/templates/rbac.yaml

# Include a clusterrole for the kube-controllers component,
# and bind it to the calico-kube-controllers serviceaccount.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
rules:
  # Nodes are watched to monitor for deletions.
  - apiGroups: [""]
    resources:
      - nodes
    verbs:
      - watch
      - list
      - get
  # Pods are queried to check for existence.
  - apiGroups: [""]
    resources:
      - pods
    verbs:
      - get
  # IPAM resources are manipulated when nodes are deleted.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - ippools
    verbs:
      - list
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - blockaffinities
      - ipamblocks
      - ipamhandles
    verbs:
      - get
      - list
      - create
      - update
      - delete
  # Needs access to update clusterinformations.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - clusterinformations
    verbs:
      - get
      - create
      - update
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-kube-controllers
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-kube-controllers
subjects:
- kind: ServiceAccount
  name: calico-kube-controllers
  namespace: kube-system
---
# Include a clusterrole for the calico-node DaemonSet,
# and bind it to the calico-node serviceaccount.
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: calico-node
rules:
  # The CNI plugin needs to get pods, nodes, and namespaces.
  - apiGroups: [""]
    resources:
      - pods
      - nodes
      - namespaces
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - endpoints
      - services
    verbs:
      # Used to discover service IPs for advertisement.
      - watch
      - list
      # Used to discover Typhas.
      - get
  # Pod CIDR auto-detection on kubeadm needs access to config maps.
  - apiGroups: [""]
    resources:
      - configmaps
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - nodes/status
    verbs:
      # Needed for clearing NodeNetworkUnavailable flag.
      - patch
      # Calico stores some configuration information in node annotations.
      - update
  # Watch for changes to Kubernetes NetworkPolicies.
  - apiGroups: ["networking.k8s.io"]
    resources:
      - networkpolicies
    verbs:
      - watch
      - list
  # Used by Calico for policy information.
  - apiGroups: [""]
    resources:
      - pods
      - namespaces
      - serviceaccounts
    verbs:
      - list
      - watch
  # The CNI plugin patches pods/status.
  - apiGroups: [""]
    resources:
      - pods/status
    verbs:
      - patch
  # Calico monitors various CRDs for config.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - globalfelixconfigs
      - felixconfigurations
      - bgppeers
      - globalbgpconfigs
      - bgpconfigurations
      - ippools
      - ipamblocks
      - globalnetworkpolicies
      - globalnetworksets
      - networkpolicies
      - networksets
      - clusterinformations
      - hostendpoints
      - blockaffinities
    verbs:
      - get
      - list
      - watch
  # Calico must create and update some CRDs on startup.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - ippools
      - felixconfigurations
      - clusterinformations
    verbs:
      - create
      - update
  # Calico stores some configuration information on the node.
  - apiGroups: [""]
    resources:
      - nodes
    verbs:
      - get
      - list
      - watch
  # These permissions are only requried for upgrade from v2.6, and can
  # be removed after upgrade or on fresh installations.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - bgpconfigurations
      - bgppeers
    verbs:
      - create
      - update
  # These permissions are required for Calico CNI to perform IPAM allocations.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - blockaffinities
      - ipamblocks
      - ipamhandles
    verbs:
      - get
      - list
      - create
      - update
      - delete
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - ipamconfigs
    verbs:
      - get
  # Block affinities must also be watchable by confd for route aggregation.
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - blockaffinities
    verbs:
      - watch
  # The Calico IPAM migration needs to get daemonsets. These permissions can be
  # removed if not upgrading from an installation using host-local IPAM.
  - apiGroups: ["apps"]
    resources:
      - daemonsets
    verbs:
      - get

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: calico-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: calico-node
subjects:
- kind: ServiceAccount
  name: calico-node
  namespace: kube-system

---
# Source: calico/templates/calico-node.yaml
# This manifest installs the calico-node container, as well
# as the CNI plugins and network config on
# each master and worker node in a Kubernetes cluster.
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: calico-node
  namespace: kube-system
  labels:
    k8s-app: calico-node
spec:
  selector:
    matchLabels:
      k8s-app: calico-node
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        k8s-app: calico-node
      annotations:
        # This, along with the CriticalAddonsOnly toleration below,
        # marks the pod as a critical add-on, ensuring it gets
        # priority scheduling and that its resources are reserved
        # if it ever gets evicted.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        kubernetes.io/os: linux
      hostNetwork: true
      tolerations:
        # Make sure calico-node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      serviceAccountName: calico-node
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      priorityClassName: system-node-critical
      initContainers:
        # This container performs upgrade from host-local IPAM to calico-ipam.
        # It can be deleted if this is a fresh installation, or if you have already
        # upgraded to use calico-ipam.
        - name: upgrade-ipam
          image: calico/cni:v3.13.1
          command: ["/opt/cni/bin/calico-ipam", "-upgrade"]
          env:
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
          volumeMounts:
            - mountPath: /var/lib/cni/networks
              name: host-local-net-dir
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
          securityContext:
            privileged: true
        # This container installs the CNI binaries
        # and CNI network config file on each node.
        - name: install-cni
          image: calico/cni:v3.13.1
          command: ["/install-cni.sh"]
          env:
            # Name of the CNI config file to create.
            - name: CNI_CONF_NAME
              value: "10-calico.conflist"
            # The CNI network config to install on each node.
            - name: CNI_NETWORK_CONFIG
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: cni_network_config
            # Set the hostname based on the k8s node name.
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # CNI MTU Config variable
            - name: CNI_MTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # Prevents the container from sleeping forever.
            - name: SLEEP
              value: "false"
          volumeMounts:
            - mountPath: /host/opt/cni/bin
              name: cni-bin-dir
            - mountPath: /host/etc/cni/net.d
              name: cni-net-dir
          securityContext:
            privileged: true
        # Adds a Flex Volume Driver that creates a per-pod Unix Domain Socket to allow Dikastes
        # to communicate with Felix over the Policy Sync API.
        - name: flexvol-driver
          image: calico/pod2daemon-flexvol:v3.13.1
          volumeMounts:
          - name: flexvol-driver-host
            mountPath: /host/driver
          securityContext:
            privileged: true
      containers:
        # Runs calico-node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: calico/node:v3.13.1
          env:
            # Use Kubernetes API as the backing datastore.
            - name: DATASTORE_TYPE
              value: "kubernetes"
            # Wait for the datastore.
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # Choose the backend to use.
            - name: CALICO_NETWORKING_BACKEND
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: calico_backend
            # Cluster type to identify the deployment type
            - name: CLUSTER_TYPE
              value: "k8s,bgp"
            # Auto-detect the BGP IP address.
            - name: IP
              value: "autodetect"
            # Enable IPIP
            - name: CALICO_IPV4POOL_IPIP
              value: "Always"
            # Set MTU for tunnel device used if ipip is enabled
            - name: FELIX_IPINIPMTU
              valueFrom:
                configMapKeyRef:
                  name: calico-config
                  key: veth_mtu
            # The default IPv4 pool to create on startup if none exists. Pod IPs will be
            # chosen from this range. Changing this value after installation will have
            # no effect. This should fall within `--cluster-cidr`.
            # - name: CALICO_IPV4POOL_CIDR
            #   value: "192.168.0.0/16"
            # Disable file logging so `kubectl logs` works.
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            # Set Felix endpoint to host default action to ACCEPT.
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            # Disable IPv6 on Kubernetes.
            - name: FELIX_IPV6SUPPORT
              value: "false"
            # Set Felix logging to "info"
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            - name: FELIX_HEALTHENABLED
              value: "true"
          securityContext:
            privileged: true
          resources:
            requests:
              cpu: 250m
          livenessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-live
              - -bird-live
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
              - /bin/calico-node
              - -felix-ready
              - -bird-ready
            periodSeconds: 10
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
            - name: policysync
              mountPath: /var/run/nodeagent
      volumes:
        # Used by calico-node.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
        # Used to install CNI.
        - name: cni-bin-dir
          hostPath:
            path: /opt/cni/bin
        - name: cni-net-dir
          hostPath:
            path: /etc/cni/net.d
        # Mount in the directory for host-local IPAM allocations. This is
        # used when upgrading from host-local to calico-ipam, and can be removed
        # if not using the upgrade-ipam init container.
        - name: host-local-net-dir
          hostPath:
            path: /var/lib/cni/networks
        # Used to create per-pod Unix Domain Sockets
        - name: policysync
          hostPath:
            type: DirectoryOrCreate
            path: /var/run/nodeagent
        # Used to install Flex Volume Driver
        - name: flexvol-driver-host
          hostPath:
            type: DirectoryOrCreate
            path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/nodeagent~uds
---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-node
  namespace: kube-system

---
# Source: calico/templates/calico-kube-controllers.yaml

# See https://github.com/projectcalico/kube-controllers
apiVersion: apps/v1
kind: Deployment
metadata:
  name: calico-kube-controllers
  namespace: kube-system
  labels:
    k8s-app: calico-kube-controllers
spec:
  # The controllers can only have a single active instance.
  replicas: 1
  selector:
    matchLabels:
      k8s-app: calico-kube-controllers
  strategy:
    type: Recreate
  template:
    metadata:
      name: calico-kube-controllers
      namespace: kube-system
      labels:
        k8s-app: calico-kube-controllers
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      nodeSelector:
        kubernetes.io/os: linux
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      serviceAccountName: calico-kube-controllers
      priorityClassName: system-cluster-critical
      containers:
        - name: calico-kube-controllers
          image: calico/kube-controllers:v3.13.1
          env:
            # Choose which controllers to run.
            - name: ENABLED_CONTROLLERS
              value: node
            - name: DATASTORE_TYPE
              value: kubernetes
          readinessProbe:
            exec:
              command:
              - /usr/bin/check-status
              - -r

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: calico-kube-controllers
  namespace: kube-system
---
# Source: calico/templates/calico-etcd-secrets.yaml

---
# Source: calico/templates/calico-typha.yaml

---
# Source: calico/templates/configure-canal.yaml
```

å¦‚æœå®‰è£…å‡ºé”™ï¼Œè¯·æ£€æŸ¥å¦‚ä¸‹éƒ¨åˆ†ï¼š

* è¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒç¬¦åˆ [å®‰è£…dockeråŠkubelet](#å®‰è£…dockeråŠkubelet) ä¸­æ‰€æœ‰å‹¾é€‰æ¡†çš„è¦æ±‚
* è¯·ç¡®ä¿æ‚¨ä½¿ç”¨ root ç”¨æˆ·æ‰§è¡Œåˆå§‹åŒ–å‘½ä»¤
* ä¸èƒ½ä¸‹è½½ kubernetes çš„ docker é•œåƒ
  * å®‰è£…æ–‡æ¡£ä¸­ï¼Œé»˜è®¤ä½¿ç”¨é˜¿é‡Œäº‘çš„ docker é•œåƒä»“åº“ï¼Œç„¶è€Œï¼Œæœ‰æ—¶å€™ï¼Œè¯¥é•œåƒä¼šç½¢å·¥
  * å¦‚ç¢°åˆ°ä¸èƒ½ä¸‹è½½ docker é•œåƒçš„æƒ…å†µï¼Œè¯·å°è¯•æ‰‹å·¥åˆå§‹åŒ–ï¼Œå¹¶ä¿®æ”¹æ‰‹å·¥åˆå§‹åŒ–è„šæœ¬é‡Œçš„ç¬¬22è¡Œï¼ˆæ–‡æ¡£ä¸­å·²é«˜äº®ï¼‰ä¸ºï¼š
    ```yaml
    imageRepository: gcr.azk8s.cn/google-containers
    ```
* æ£€æŸ¥ç¯å¢ƒå˜é‡ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤
  ``` sh
  echo MASTER_IP=${MASTER_IP} && echo APISERVER_NAME=${APISERVER_NAME} && echo POD_SUBNET=${POD_SUBNET}
  ```
  è¯·éªŒè¯å¦‚ä¸‹å‡ ç‚¹ï¼š
  * ç¯å¢ƒå˜é‡ ***MASTER_IP*** çš„å€¼åº”è¯¥ä¸º master èŠ‚ç‚¹çš„ **å†…ç½‘IP**ï¼Œå¦‚æœä¸æ˜¯ï¼Œè¯·é‡æ–° export
  * **APISERVER_NAME** ä¸èƒ½æ˜¯ master çš„ hostname
  * **APISERVER_NAME** å¿…é¡»å…¨ä¸ºå°å†™å­—æ¯ã€æ•°å­—ã€å°æ•°ç‚¹ï¼Œä¸èƒ½åŒ…å«å‡å·
  * **POD_SUBNET** æ‰€ä½¿ç”¨çš„ç½‘æ®µä¸èƒ½ä¸ ***masterèŠ‚ç‚¹/workerèŠ‚ç‚¹*** æ‰€åœ¨çš„ç½‘æ®µé‡å ã€‚è¯¥å­—æ®µçš„å–å€¼ä¸ºä¸€ä¸ª <a href="/glossary/cidr.html" target="_blank">CIDR</a> å€¼ï¼Œå¦‚æœæ‚¨å¯¹ CIDR è¿™ä¸ªæ¦‚å¿µè¿˜ä¸ç†Ÿæ‚‰ï¼Œè¯·ä»ç„¶æ‰§è¡Œ export POD_SUBNET=10.100.0.1/16 å‘½ä»¤ï¼Œä¸åšä¿®æ”¹
* é‡æ–°åˆå§‹åŒ– master èŠ‚ç‚¹å‰ï¼Œè¯·å…ˆæ‰§è¡Œ `kubeadm reset -f` æ“ä½œ

**æ£€æŸ¥ master åˆå§‹åŒ–ç»“æœ**

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ

# æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œç­‰å¾… 3-10 åˆ†é’Ÿï¼Œç›´åˆ°æ‰€æœ‰çš„å®¹å™¨ç»„å¤„äº Running çŠ¶æ€
watch kubectl get pod -n kube-system -o wide

# æŸ¥çœ‹ master èŠ‚ç‚¹åˆå§‹åŒ–ç»“æœ
kubectl get nodes -o wide
```

## åˆå§‹åŒ– workerèŠ‚ç‚¹

### è·å¾— joinå‘½ä»¤å‚æ•°

**åœ¨ master èŠ‚ç‚¹ä¸Šæ‰§è¡Œ**

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubeadm token create --print-join-command
```

> tip æœ‰æ•ˆæ—¶é—´
> è¯¥ token çš„æœ‰æ•ˆæ—¶é—´ä¸º 2 ä¸ªå°æ—¶ï¼Œ2å°æ—¶å†…ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ­¤ token åˆå§‹åŒ–ä»»æ„æ•°é‡çš„ worker èŠ‚ç‚¹ã€‚

### åˆå§‹åŒ–worker

**é’ˆå¯¹æ‰€æœ‰çš„ worker èŠ‚ç‚¹æ‰§è¡Œ**

``` sh
# åªåœ¨ worker èŠ‚ç‚¹æ‰§è¡Œ
# æ›¿æ¢ x.x.x.x ä¸º master èŠ‚ç‚¹çš„å†…ç½‘ IP
export MASTER_IP=x.x.x.x
# æ›¿æ¢ apiserver.demo ä¸ºåˆå§‹åŒ– master èŠ‚ç‚¹æ—¶æ‰€ä½¿ç”¨çš„ APISERVER_NAME
export APISERVER_NAME=apiserver.demo
echo "${MASTER_IP}    ${APISERVER_NAME}" >> /etc/hosts

# æ›¿æ¢ä¸º master èŠ‚ç‚¹ä¸Š kubeadm token create å‘½ä»¤çš„è¾“å‡º
kubeadm join apiserver.demo:6443 --token mpfjma.4vjjg8flqihor4vt     --discovery-token-ca-cert-hash sha256:6f7a8e40a810323672de5eee6f4d19aa2dbdb38411845a1bf5dd63485c43d303
```

### å¸¸è§é”™è¯¯åŸå› 

ä¸ºä»€ä¹ˆ join ä¸æˆåŠŸçš„æƒ…å†µå¤§è‡´æœ‰è¿™å‡ ç§ï¼š

#### worker èŠ‚ç‚¹ä¸èƒ½è®¿é—® apiserver

  åœ¨workerèŠ‚ç‚¹æ‰§è¡Œä»¥ä¸‹è¯­å¥å¯éªŒè¯workerèŠ‚ç‚¹æ˜¯å¦èƒ½è®¿é—® apiserver
  ``` sh
  curl -ik https://apiserver.demo:6443
  ```
  å¦‚æœä¸èƒ½ï¼Œè¯·åœ¨ master èŠ‚ç‚¹ä¸ŠéªŒè¯
  ``` sh
  curl -ik https://localhost:6443
  ```
  æ­£å¸¸è¾“å‡ºç»“æœå¦‚ä¸‹æ‰€ç¤ºï¼š
  ``` 
  HTTP/1.1 403 Forbidden
  Cache-Control: no-cache, private
  Content-Type: application/json
  X-Content-Type-Options: nosniff
  Date: Fri, 15 Nov 2019 04:34:40 GMT
  Content-Length: 233

  {
    "kind": "Status",
    "apiVersion": "v1",
    "metadata": {
  ...
  ```
  > å¯èƒ½åŸå› 
  > * å¦‚æœ master èŠ‚ç‚¹èƒ½å¤Ÿè®¿é—® apiserverã€è€Œ worker èŠ‚ç‚¹ä¸èƒ½ï¼Œåˆ™è¯·æ£€æŸ¥è‡ªå·±çš„ç½‘ç»œè®¾ç½®
  >  * /etc/hosts æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼Ÿ
  >  * æ˜¯å¦æœ‰å®‰å…¨ç»„æˆ–é˜²ç«å¢™çš„é™åˆ¶ï¼Ÿ

#### worker èŠ‚ç‚¹é»˜è®¤ç½‘å¡
  
  * [Kubeletä½¿ç”¨çš„ IP åœ°å€](#æ£€æŸ¥ç½‘ç»œ) ä¸ master èŠ‚ç‚¹å¯äº’é€šï¼ˆæ— éœ€ NAT æ˜ å°„ï¼‰ï¼Œä¸”æ²¡æœ‰é˜²ç«å¢™ã€å®‰å…¨ç»„éš”ç¦»
    * å¦‚æœä½ ä½¿ç”¨ vmware æˆ– virtualbox åˆ›å»ºè™šæ‹Ÿæœºç”¨äº K8S å­¦ä¹ ï¼Œå¯ä»¥å°è¯• NAT æ¨¡å¼çš„ç½‘ç»œï¼Œè€Œä¸æ˜¯æ¡¥æ¥æ¨¡å¼çš„ç½‘ç»œ

### ç§»é™¤workerèŠ‚ç‚¹å¹¶é‡è¯•

> warning
> æ­£å¸¸æƒ…å†µä¸‹ï¼Œæ‚¨æ— éœ€ç§»é™¤ worker èŠ‚ç‚¹ï¼Œå¦‚æœæ·»åŠ åˆ°é›†ç¾¤å‡ºé”™ï¼Œæ‚¨å¯ä»¥ç§»é™¤ worker èŠ‚ç‚¹ï¼Œå†é‡æ–°å°è¯•æ·»åŠ 

åœ¨å‡†å¤‡ç§»é™¤çš„ worker èŠ‚ç‚¹ä¸Šæ‰§è¡Œ

``` sh
# åªåœ¨ worker èŠ‚ç‚¹æ‰§è¡Œ
kubeadm reset -f
```

åœ¨ master èŠ‚ç‚¹ demo-master-a-1 ä¸Šæ‰§è¡Œ

```sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubectl get nodes -o wide
```
å¦‚æœåˆ—è¡¨ä¸­æ²¡æœ‰æ‚¨è¦ç§»é™¤çš„èŠ‚ç‚¹ï¼Œåˆ™å¿½ç•¥ä¸‹ä¸€ä¸ªæ­¥éª¤

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubectl delete node demo-worker-x-x
```

> tip
> * å°† demo-worker-x-x æ›¿æ¢ä¸ºè¦ç§»é™¤çš„ worker èŠ‚ç‚¹çš„åå­—
> * worker èŠ‚ç‚¹çš„åå­—å¯ä»¥é€šè¿‡åœ¨èŠ‚ç‚¹ demo-master-a-1 ä¸Šæ‰§è¡Œ kubectl get nodes å‘½ä»¤è·å¾—

### æ£€æŸ¥åˆå§‹åŒ–ç»“æœ

åœ¨ master èŠ‚ç‚¹ä¸Šæ‰§è¡Œ

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubectl get nodes -o wide
```
è¾“å‡ºç»“æœå‚è€ƒå¦‚ä¸‹æ‰€ç¤ºï¼š
```sh
[root@demo-master-a-1 ~]# kubectl get nodes
NAME     STATUS   ROLES    AGE     VERSION
demo-master-a-1   Ready    master   5m3s    v1.19.x
demo-worker-a-1   Ready    <none>   2m26s   v1.19.x
demo-worker-a-2   Ready    <none>   3m56s   v1.19.x
```

## å®‰è£… Ingress Controller

**åœ¨ master èŠ‚ç‚¹ä¸Šæ‰§è¡Œ**

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubectl apply -f https://kuboard.cn/install-script/v1.19.x/nginx-ingress.yaml
```

**åœ¨ master èŠ‚ç‚¹ä¸Šæ‰§è¡Œ**

åªåœ¨æ‚¨æƒ³é€‰æ‹©å…¶ä»– Ingress Controller çš„æƒ…å†µä¸‹å¸è½½

``` sh
# åªåœ¨ master èŠ‚ç‚¹æ‰§è¡Œ
kubectl delete -f https://kuboard.cn/install-script/v1.19.x/nginx-ingress.yaml
```

nginx-ingress.yamlæ–‡ä»¶å†…å®¹ï¼Œè¿™é‡Œåªä½œå¤‡ä»½ï¼š

``` yaml
# å¦‚æœæ‰“ç®—ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œè¯·å‚è€ƒ https://github.com/nginxinc/kubernetes-ingress/blob/v1.5.5/docs/installation.md å¹¶æ ¹æ®æ‚¨è‡ªå·±çš„æƒ…å†µåšè¿›ä¸€æ­¥å®šåˆ¶

apiVersion: v1
kind: Namespace
metadata:
  name: nginx-ingress

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nginx-ingress 
  namespace: nginx-ingress

---
apiVersion: v1
kind: Secret
metadata:
  name: default-server-secret
  namespace: nginx-ingress
type: Opaque
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUN2akNDQWFZQ0NRREFPRjl0THNhWFhEQU5CZ2txaGtpRzl3MEJBUXNGQURBaE1SOHdIUVlEVlFRRERCWk8KUjBsT1dFbHVaM0psYzNORGIyNTBjbTlzYkdWeU1CNFhEVEU0TURreE1qRTRNRE16TlZvWERUSXpNRGt4TVRFNApNRE16TlZvd0lURWZNQjBHQTFVRUF3d1dUa2RKVGxoSmJtZHlaWE56UTI5dWRISnZiR3hsY2pDQ0FTSXdEUVlKCktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUwvN2hIUEtFWGRMdjNyaUM3QlBrMTNpWkt5eTlyQ08KR2xZUXYyK2EzUDF0azIrS3YwVGF5aGRCbDRrcnNUcTZzZm8vWUk1Y2Vhbkw4WGM3U1pyQkVRYm9EN2REbWs1Qgo4eDZLS2xHWU5IWlg0Rm5UZ0VPaStlM2ptTFFxRlBSY1kzVnNPazFFeUZBL0JnWlJVbkNHZUtGeERSN0tQdGhyCmtqSXVuektURXUyaDU4Tlp0S21ScUJHdDEwcTNRYzhZT3ExM2FnbmovUWRjc0ZYYTJnMjB1K1lYZDdoZ3krZksKWk4vVUkxQUQ0YzZyM1lma1ZWUmVHd1lxQVp1WXN2V0RKbW1GNWRwdEMzN011cDBPRUxVTExSakZJOTZXNXIwSAo1TmdPc25NWFJNV1hYVlpiNWRxT3R0SmRtS3FhZ25TZ1JQQVpQN2MwQjFQU2FqYzZjNGZRVXpNQ0F3RUFBVEFOCkJna3Foa2lHOXcwQkFRc0ZBQU9DQVFFQWpLb2tRdGRPcEsrTzhibWVPc3lySmdJSXJycVFVY2ZOUitjb0hZVUoKdGhrYnhITFMzR3VBTWI5dm15VExPY2xxeC9aYzJPblEwMEJCLzlTb0swcitFZ1U2UlVrRWtWcitTTFA3NTdUWgozZWI4dmdPdEduMS9ienM3bzNBaS9kclkrcUI5Q2k1S3lPc3FHTG1US2xFaUtOYkcyR1ZyTWxjS0ZYQU80YTY3Cklnc1hzYktNbTQwV1U3cG9mcGltU1ZmaXFSdkV5YmN3N0NYODF6cFErUyt1eHRYK2VBZ3V0NHh3VlI5d2IyVXYKelhuZk9HbWhWNThDd1dIQnNKa0kxNXhaa2VUWXdSN0diaEFMSkZUUkk3dkhvQXprTWIzbjAxQjQyWjNrN3RXNQpJUDFmTlpIOFUvOWxiUHNoT21FRFZkdjF5ZytVRVJxbStGSis2R0oxeFJGcGZnPT0KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
  tls.key: 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

---
kind: ConfigMap
apiVersion: v1
metadata:
  name: nginx-config
  namespace: nginx-ingress
data:
  server-names-hash-bucket-size: "1024"


---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress
rules:
- apiGroups:
  - ""
  resources:
  - services
  - endpoints
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - secrets
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - update
  - create
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - "extensions"
  resources:
  - ingresses/status
  verbs:
  - update
- apiGroups:
  - k8s.nginx.org
  resources:
  - virtualservers
  - virtualserverroutes
  verbs:
  - list
  - watch
  - get

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: nginx-ingress
subjects:
- kind: ServiceAccount
  name: nginx-ingress
  namespace: nginx-ingress
roleRef:
  kind: ClusterRole
  name: nginx-ingress
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nginx-ingress
  namespace: nginx-ingress
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9113"
spec:
  selector:
    matchLabels:
      app: nginx-ingress
  template:
    metadata:
      labels:
        app: nginx-ingress
    spec:
      serviceAccountName: nginx-ingress
      containers:
      - image: nginx/nginx-ingress:1.5.5
        name: nginx-ingress
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: https
          containerPort: 443
          hostPort: 443
        - name: prometheus
          containerPort: 9113
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        args:
          - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config
          - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret
         #- -v=3 # Enables extensive logging. Useful for troubleshooting.
         #- -report-ingress-status
         #- -external-service=nginx-ingress
         #- -enable-leader-election
          - -enable-prometheus-metrics
         #- -enable-custom-resources
```

**é…ç½®åŸŸåè§£æ**

å°†åŸŸå *.demo.yourdomain.com è§£æåˆ° demo-worker-a-2 çš„ IP åœ°å€ z.z.z.z ï¼ˆä¹Ÿå¯ä»¥æ˜¯ demo-worker-a-1 çš„åœ°å€ y.y.y.yï¼‰

**éªŒè¯é…ç½®**

åœ¨æµè§ˆå™¨è®¿é—® a.demo.yourdomain.comï¼Œå°†å¾—åˆ° 404 NotFound é”™è¯¯é¡µé¢

> tip æç¤º
> è®¸å¤šåˆå­¦è€…åœ¨å®‰è£… Ingress Controller æ—¶ä¼šç¢°åˆ°é—®é¢˜ï¼Œè¯·ä¸è¦ç°å¿ƒï¼Œå¯æš‚æ—¶è·³è¿‡ ***å®‰è£… Ingress Controller*** è¿™ä¸ªéƒ¨åˆ†
> ä¹Ÿå¯ä»¥å‚è€ƒ [Install Nginx Ingress](https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/)
> å¦‚æœæ‰“ç®—å°† Kubernetes ç”¨äºç”Ÿäº§ç¯å¢ƒï¼Œè¯·å‚è€ƒæ­¤æ–‡æ¡£ [Installing Ingress Controller](https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/)ï¼Œå®Œå–„ Ingress çš„é…ç½®

æœ¬æ–‡è®²è§£äº†é€šè¿‡ kubeadm å®‰è£… k8s å• master èŠ‚ç‚¹ï¼Œé€‚åˆåˆå­¦å’Œæµ‹è¯•ä½¿ç”¨ï¼Œå¦‚æœè¦ä½¿ç”¨äºŒè¿›åˆ¶å®‰è£…ï¼Œè¯·å‚è€ƒ [ä½¿ç”¨äºŒè¿›åˆ¶çš„æ–¹å¼éƒ¨ç½² K8S-1.16 é«˜å¯ç”¨é›†ç¾¤](https://blog.51cto.com/wzlinux/2451105)å’Œ[å’Œæˆ‘ä¸€æ­¥æ­¥éƒ¨ç½² kubernetes é›†ç¾¤
](https://k8s-install.opsnull.com/)ï¼Œè¿˜æœ‰ [ä½¿ç”¨Ansibleè„šæœ¬å®‰è£…K8Sé›†ç¾¤](https://github.com/easzlab/kubeasz)

## Reference

- [ä½¿ç”¨kubeadmå®‰è£…kubernetes_v1.19.x](https://www.kuboard.cn/install/install-k8s.html)
